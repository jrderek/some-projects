{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_jMBTKtPWTP4"
   },
   "source": [
    "**TIME SERIES ANALYSIS FOR STOCK MARKET DATA SPECIFICALLY AMAZON. DATA SOURCE IS YAHOO.API AND ALPHADVANTAGE.API**\n",
    "\n",
    "**This notebook is Part 1 of Time series modelling for Amazon Stock Prediction\n",
    "It deals with:**\n",
    "\n",
    "**1.   Data Exploration**\n",
    "\n",
    "**2.   Making a time series window**\n",
    "\n",
    "**3.   Feature engineering from the data**\n",
    "\n",
    "**4. Make an ARIMA model**\n",
    "\n",
    "**5. Make a Fourier series mode**l\n",
    "\n",
    "**6. Make a LSTM model with one feature**\n",
    "\n",
    "**7.Make a LSTM model with multiple features**\n",
    "\n",
    "**8.Conclusion**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VGNrO7RQor0w"
   },
   "source": [
    "**Level 0: INSTALLATION**\n",
    "\n",
    "**1.   Set up modules on google colab**\n",
    "\n",
    "**2.  Take in data from yahoo.api**\n",
    "\n",
    "**3. For privacy of my own account I have blocked these links and API keys off**\n",
    "\n",
    "**Hint: Google colab Python 3 version comes with all Python packages and modules. It's easier to use than Anaconda or Ubuntu and has a great GPU drive.** \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_xc364gbUKMG"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydrive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v9/nv1t6g591m18kqp9zx75tqcc0000gn/T/ipykernel_92179/3609505251.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -U -q PyDrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrive\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleDrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydrive'"
     ]
    }
   ],
   "source": [
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6xka10QxqrBE"
   },
   "source": [
    "**Use the code above to set up Drive which will have csv file.**\n",
    "\n",
    "Credit: https://medium.com/paper-club/how-to-set-up-google-colab-colaboratory-for-building-pyro-models-8e51129e772a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FpGd27iPApW9"
   },
   "outputs": [],
   "source": [
    "link = 'https://drive.google.com/open?id=1y394o-wiPqYPaWzVYTPRr8xpE_aM9621'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjpKSbnqtdj8"
   },
   "source": [
    "**Link to your google drive. This will make your drive public to all so be careful who you give it to.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1013,
     "status": "ok",
     "timestamp": 1565975573593,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "1NBd-Hx7Auif",
    "outputId": "fe3624bf-6174-4d54-d88f-8a6c33aa72f2"
   },
   "outputs": [],
   "source": [
    "fluff, id = link.split('=')\n",
    "print (id) # Verify that you have everything after '='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9EP87twmttME"
   },
   "source": [
    "**To check I got data in my file and it's been read**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vnt8KyUA885"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('AMZN.csv')\n",
    "# Dataset is now stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4861,
     "status": "ok",
     "timestamp": 1565975579812,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "XeoyRs8hCwTX",
    "outputId": "8a36fc84-b64f-4bf7-9025-b34889d034ae"
   },
   "outputs": [],
   "source": [
    "pip install mxnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Encu5lTtt215"
   },
   "source": [
    "**install mxnet a python package for time series data great for visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-n42rXkBY4x"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxnet.gluon import nn, rnn\n",
    "import mxnet as mx\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nGy43Rr9FAhT"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "acikqo6lVWgM"
   },
   "outputs": [],
   "source": [
    "context = mx.cpu(); model_ctx=mx.cpu()\n",
    "mx.random.seed(1719)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7qUPd_qSuiaI"
   },
   "source": [
    "Setting up mxnet model \n",
    "Need this to create an ARIMA model and Fourier series model easily "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuwLSx1BVjK7"
   },
   "outputs": [],
   "source": [
    "def parser(x):\n",
    "    return datetime.datetime.strptime(x,'%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oGloNVdKu4ZQ"
   },
   "source": [
    "**Always sort time and format it properily for time series data. Here sorted out it month-date-year format.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iIX76FltX8yD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u33F4vKcHEjU"
   },
   "outputs": [],
   "source": [
    "dataset_ex_df = pd.read_csv(\"AMZN.csv\", header=0, parse_dates=[0], date_parser=parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 740,
     "status": "ok",
     "timestamp": 1565975595063,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "8pMM2w-cHsv3",
    "outputId": "220c2f58-0217-4a5e-f7f5-fc0e286bf7ff"
   },
   "outputs": [],
   "source": [
    "dataset_ex_df[['Date', 'Close']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AVkU6X93veJp"
   },
   "source": [
    "**Have a good look at closing prices and date. Most time series analysis go with trying to fo find closing prices.** \n",
    "**The reason is because closing prices generally summarize the way business was going better than opening prices or average prices.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1158,
     "status": "ok",
     "timestamp": 1565975597982,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "6a3PaysYHx2i",
    "outputId": "98fdf40f-7abc-4051-bda9-3619bba54020"
   },
   "outputs": [],
   "source": [
    "print('There are {} number of days in the dataset.'.format(dataset_ex_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1794,
     "status": "ok",
     "timestamp": 1565975600441,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "jDVWPQqQIPSg",
    "outputId": "d50a57eb-6b13-41eb-a094-cc22d789f02e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5), dpi=100)\n",
    "plt.plot(dataset_ex_df['Date'], dataset_ex_df['Close'], label='Amazon stock')\n",
    "plt.vlines(datetime.date(2016,4,20), 0, 270, linestyles='--', colors='gray', label='Train/Test data cut-off')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('USD')\n",
    "plt.title('Figure 2: Amazon stock price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PTLPUwUqxsFn"
   },
   "source": [
    "**I have divided the stock data after 2010 upto 2019 for Amazon. \n",
    "Amazon business really boomed after 2010 and then peaked after 2015 so the testing will be very interesting since most of the data is in the exponential growth period. What I am going to do it normalize the training data such that similar data points over time are reduced to one single data point so that the model can train in such a way it can expect the exponential growth after 2015.**\n",
    "\n",
    "**Inorder to predict better i NEED TO GENERATOR FEATURES SO I HAVE MORE INDICATORS TO PREDICT THE DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUrq9syJy4FM"
   },
   "source": [
    "# **FEATURE GENERATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pq8-28ZxITgE"
   },
   "outputs": [],
   "source": [
    "def get_technical_indicators(dataset): #function to generate feature technical indicators\n",
    "    \n",
    "    \n",
    "    # Create 7 and 21 days Moving Average\n",
    "    dataset['ma7'] = dataset['Close'].rolling(window = 7).mean()\n",
    "    dataset['ma21'] = dataset['Close'].rolling(window = 21).mean()\n",
    "    \n",
    "    #Create MACD\n",
    "    dataset['26ema'] = dataset['Close'].ewm(span=26).mean()\n",
    "    dataset['12ema'] = dataset['Close'].ewm(span=12).mean()\n",
    "    dataset['MACD'] = (dataset['12ema']-dataset['26ema'])\n",
    "    \n",
    "    #Create Bollinger Bands\n",
    "    dataset['20sd'] = dataset['Close'].rolling(window = 20).std()\n",
    "    dataset['upper_band'] = (dataset['Close'].rolling(window = 20).mean()) + (dataset['20sd']*2)\n",
    "    dataset['lower_band'] = (dataset['Close'].rolling(window = 20).mean()) - (dataset['20sd']*2)\n",
    "    \n",
    "    \n",
    "    #Create Exponential moving average\n",
    "    dataset['ema'] = dataset['Close'].ewm(com=0.5).mean()\n",
    "    \n",
    "    #Create Momentum\n",
    "    dataset['momentum'] = (dataset['Close']/100)-1\n",
    "    \n",
    "    \n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XfaBgjfrzPJm"
   },
   "source": [
    "**List of technical indicators and explanation:**\n",
    "\n",
    "\n",
    "**1.   Bollinger bands: Bollinger Bands is used to define the prevailing high and low prices in a market to characterize the trading band of a financial instrument or commodity. Bollinger Bands are a volatility indicator. Bands are consists of Moving Average (MA) line, a upper band and lower band. The upper and lower bands are simply MA adding and subtracting standard deviation.** \n",
    "\n",
    "**2.   EMA: Exponential moving average is a better version of a simple moving average that doesnt have SMAs lag. Moving averages just average out the data for a given time so we know how the company's closing price are trending for a given amount of days. example for 4 days is price was 22,23 ,45,1**\n",
    "**(the company crashed on 4th day) the average would be 23. Now 23 is a below average value so it gives us an idea that 45 was indeed just a fluke and that infact the company was always making losses**\n",
    "**EMA is calculated as:**\n",
    "**EMA(t)EMA(t0)=(1−α)EMA(t−1)+α p(t)=p(t0)**\n",
    "**where** \n",
    "**α=1L+1 and length of window is α=2M+1**\n",
    "**I used the ewm(exponential weighted mean ) function to calculate ema.**\n",
    "\n",
    "\n",
    "\n",
    "**3. Momentum: Momentum is perhaps the simplest and easiest oscillator (financial analysis tool) to understand and use. It is the measurement of the speed or velocity of price changes, or the rate of change in price movement for a particular asset.**\n",
    "\n",
    "**The formula for momentum is:**\n",
    "\n",
    "**Momentum=V−Vx**\n",
    "**where:**\n",
    "\n",
    "**V=Latest price**\n",
    "\n",
    "**Vx=Closing price**\n",
    "\n",
    "**x=Number of days ago**\n",
    "\n",
    "\n",
    "**Other features calculated are**\n",
    "**moving averages of 7 and 21 days and standard deviation.**\n",
    "\n",
    "\n",
    "**Great Links are:**\n",
    "1. https://www.learndatasci.com/tutorials/python-finance-part-3-moving-average-trading-strategy/\n",
    "2. https://towardsdatascience.com/trading-technical-analysis-with-pandas-43e737a17861"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLLcWPw0Ij5w"
   },
   "outputs": [],
   "source": [
    "dataset_TI_df = get_technical_indicators(dataset_ex_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1234,
     "status": "ok",
     "timestamp": 1565975607000,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "r0dKh8HeImGj",
    "outputId": "d54c120f-28f8-489a-91dd-81ff8d10376c"
   },
   "outputs": [],
   "source": [
    "dataset_TI_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WI5YM1L4IoXg"
   },
   "outputs": [],
   "source": [
    "def plot_technical_indicators(dataset, last_days):\n",
    "    plt.figure(figsize=(16, 10), dpi=100)\n",
    "    shape_0 = dataset.shape[0]\n",
    "    xmacd_ = shape_0-last_days\n",
    "    \n",
    "    dataset = dataset.iloc[-last_days:, :]\n",
    "    x_ = range(3, dataset.shape[0])\n",
    "    x_ =list(dataset.index)\n",
    "    \n",
    "    # Plot first subplot\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(dataset['ma7'],label='MA 7', color='g',linestyle='--')\n",
    "    plt.plot(dataset['Close'],label='Closing Price', color='b')\n",
    "    plt.plot(dataset['ma21'],label='MA 21', color='r',linestyle='--')\n",
    "    plt.plot(dataset['upper_band'],label='Upper Band', color='c')\n",
    "    plt.plot(dataset['lower_band'],label='Lower Band', color='c')\n",
    "    plt.fill_between(x_, dataset['lower_band'], dataset['upper_band'], alpha=0.35)\n",
    "    plt.title('Technical indicators for Amazon - last {} days.'.format(last_days))\n",
    "    plt.ylabel('USD')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot second subplot\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.title('MACD')\n",
    "    plt.plot(dataset['MACD'],label='MACD', linestyle='-.')\n",
    "    plt.hlines(15, xmacd_, shape_0, colors='g', linestyles='--')\n",
    "    plt.hlines(-15, xmacd_, shape_0, colors='g', linestyles='--')\n",
    "    plt.plot(dataset['momentum'],label='Momentum', color='b',linestyle='-')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 838
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3147,
     "status": "ok",
     "timestamp": 1565975610674,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "aDPdCgs_I711",
    "outputId": "091b667f-315a-4b21-d57b-27b89e8b7857"
   },
   "outputs": [],
   "source": [
    "plot_technical_indicators(dataset_TI_df, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGDJXjmK_rly"
   },
   "source": [
    "**PLOT UNDERSTANDING:** \n",
    "\n",
    "**THE FIRST PLOT IS SELF EXPLANATORY**\n",
    "\n",
    "**THE SECOND PLOT IS SHOWING THE THRESHOLD BETWEEN MACD AND MOMENTUM. AS YOU CAN SEE MOMENTUM IS GIVING AN AVERAGE VALUE OF THE MACD IN BETEEEN THE PEAK VALUES AND THE HIGHEST OR LOWEST VALUES. MACD DEPENDS ON THE MOVING AVERAGE FEATURES AS CALCULATED ABOVE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aq3LlT6lAzho"
   },
   "source": [
    "\n",
    "\n",
    ">  \n",
    "# **ANALYSIS OF TIME SERIES USING FOURIER TRANSFORM**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dyNAHsAFI-EO"
   },
   "outputs": [],
   "source": [
    "data_FT = dataset_ex_df[['Date', 'Close']]\n",
    "close_fft = np.fft.fft(np.asarray(data_FT['Close'].tolist()))\n",
    "fft_df = pd.DataFrame({'fft':close_fft})\n",
    "fft_df['absolute'] = fft_df['fft'].apply(lambda x: np.abs(x))\n",
    "fft_df['angle'] = fft_df['fft'].apply(lambda x: np.angle(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1923,
     "status": "ok",
     "timestamp": 1565975617627,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "U58-Ziw0Jq_3",
    "outputId": "2ec51045-ab8a-42f3-a273-7bd55d9b5c22"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7), dpi=100)\n",
    "fft_list = np.asarray(fft_df['fft'].tolist())\n",
    "for num_ in [3, 6, 9, 100]:\n",
    "    fft_list_m10= np.copy(fft_list); fft_list_m10[num_:-num_]=0\n",
    "    plt.plot(np.fft.ifft(fft_list_m10), label='Fourier transform with {} components'.format(num_))\n",
    "plt.plot(data_FT['Close'],  label='Real')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('USD')\n",
    "plt.title('Figure 3: Amazon (close) stock prices & Fourier transforms')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lx_CZZsMDm0U"
   },
   "source": [
    "**Fourier Transform uses many spectral components to try and train data. From time domain its converted to frequency domain and then calculated. After that it's reconverted into time domain where it's plotted.**\n",
    "**Fourier Transform as indicator helps to extract predominate cycle from a series of data**\n",
    "\n",
    "**Reference: https://www.metastock.com/customer/resources/taaz/?p=58**\n",
    "\n",
    "**In the above example we can see the spectral component of 100 is closest to the real price so we will move ahead ith 100**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S92mKcpwJtak"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_fourier(dataset):\n",
    "    data_FT = dataset[['Date', 'Close']]\n",
    "    close_fft = np.fft.fft(np.asarray(data_FT['Close'].tolist()))\n",
    "    close_fft = np.fft.ifft(close_fft)\n",
    "    close_fft\n",
    "    fft_df = pd.DataFrame({'fft':close_fft})\n",
    "    fft_df['absolute'] = fft_df['fft'].apply(lambda x: np.abs(x))\n",
    "    fft_df['angle'] = fft_df['fft'].apply(lambda x: np.angle(x))\n",
    "    fft_list = np.asarray(fft_df['fft'].tolist())\n",
    "    fft_list_m10= np.copy(fft_list); fft_list_m10[100:-100]=0\n",
    "    dataset['Fourier'] = pd.DataFrame(fft_list_m10).apply(lambda x: np.abs(x))\n",
    "    #dataset['absolute'] = dataset['Fourier'].apply(lambda x: np.abs(x))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UxWEoAzIJ0xu"
   },
   "outputs": [],
   "source": [
    "dataset_TI_df = get_fourier(dataset_ex_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1756,
     "status": "ok",
     "timestamp": 1565975621384,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "zlqkfBlQJ9ZR",
    "outputId": "81b16f3e-0866-4c8f-990a-6fa45f91a37f"
   },
   "outputs": [],
   "source": [
    "dataset_TI_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8558,
     "status": "ok",
     "timestamp": 1565975629929,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "SejcfAlJJ_qE",
    "outputId": "5c12c30e-ac56-420e-bec3-16e3d82caf06"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "items = deque(np.asarray(fft_df['absolute'].tolist()))\n",
    "items.rotate(int(np.floor(len(fft_df)/2)))\n",
    "plt.figure(figsize=(10, 7), dpi=80)\n",
    "plt.stem(items)\n",
    "plt.title('Figure 4: Components of Fourier transforms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hnlVxuAmGF2l"
   },
   "source": [
    "**Component analysis of Fourier Transform**\n",
    "**Once the spectral part of Fourier transform is removed the magnitude part is quite close to the test series values!** \n",
    "**Fourier transform is working!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "awn3X9zu_sQy"
   },
   "source": [
    "# **ARIMA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FyNX3BWLKQ5W"
   },
   "source": [
    " **ARIMA as a feature:**\n",
    "   \n",
    " **Autoregressive Integrated Moving Average (ARIMA) — This was one of the most popular techniques for predicting future values of time series data (in the pre-neural networks ages). Let’s add it and see if it comes off as an important predictive feature.**\n",
    "   \n",
    "  **ARIMA is a technique for predicting time series data. We will show how to use it, and all though ARIMA will not serve as our final prediction, we will use it as a technique to denoise the stock a little and to (possibly) extract some new patters or features.**\n",
    "  \n",
    "  **ARIMA is an acronym. This acronym is descriptive, capturing the key aspects of the model itself. Briefly, they are:**\n",
    "\n",
    "**1. AR: Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations.**\n",
    "\n",
    "**2. I: Integrated. The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.**\n",
    "\n",
    "**3. MA: Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.**\n",
    "\n",
    "**The parameters of the ARIMA model are defined as follows:**\n",
    "\n",
    "**p: The number of lag observations included in the model, also called the lag order.**\n",
    "**d: The number of times that the raw observations are differenced, also called the degree of differencing.**\n",
    "**q: The size of the moving average window, also called the order of moving average.**\n",
    "\n",
    "**STEPS FOR ARIMA**\n",
    "\n",
    "**1.Define the model by calling ARIMA() and passing in the p, d, and q parameters.**\n",
    "\n",
    "**2. The model is prepared on the training data by calling the fit() function.**\n",
    "\n",
    "**3.Predictions can be made by calling the predict() function and specifying the index of the time or times to be predicted.**\n",
    " \n",
    "**First, we fit an ARIMA(5,1,0) model. This sets the lag value to 5 for autoregression, uses a difference order of 1 to make the time series stationary, and uses a moving average model of 0.**\n",
    "\n",
    "**When fitting the model, a lot of debug information is provided about the fit of the linear regression model. We can turn this off by setting the disp argument to 0.**\n",
    "\n",
    "**Running the example prints a summary of the fit model. This summarizes the coefficient values used as well as the skill of the fit on the on the in-sample observations.**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1565975638248,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "y-pnaN4iKUNV",
    "outputId": "669909b9-31a7-421d-d26f-cc014b2d6a00"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from pandas import DataFrame\n",
    "from pandas import datetime\n",
    "\n",
    "series = data_FT['Close']\n",
    "model = ARIMA(series, order=(5, 1, 0))\n",
    "model_fit = model.fit(disp=0)\n",
    "print(model_fit.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fsUppGk6HY6m"
   },
   "source": [
    " **SUMMARY OF THE ARIMA MODEL**\n",
    " \n",
    "**A good starting point for the AR parameter of the model may be 5 which we did**\n",
    "\n",
    "**From the summary of the ARIMA we can see that most P-values are greater than 0.05 other than the last two.The model should be great!**\n",
    "\n",
    "**The difference between AIC and BIC is low so this indicates this is a good model**\n",
    "\n",
    "**Running the example, we can see that there is a positive correlation with the first 0-to-500 lags that is perhaps significant for the first 250 lags in the autocorrelation below**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1275,
     "status": "ok",
     "timestamp": 1565975641493,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "NuucJ1WqKMkR",
    "outputId": "5ed69ecb-7fba-4dc5-b5e5-8e92c0941832"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "autocorrelation_plot(series)\n",
    "plt.figure(figsize=(10, 7), dpi=80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "naxBofp9ehfi"
   },
   "source": [
    "**Refernce to ARIMA code:**\n",
    "\n",
    "https://towardsdatascience.com/forecasting-exchange-rates-using-arima-in-python-f032f313fc56\n",
    "\n",
    "https://github.com/gmonaci/ARIMA\n",
    "\n",
    "**ARIMA Explantion :**\n",
    "\n",
    "https://towardsdatascience.com/forecasting-exchange-rates-using-arima-in-python-f032f313fc56\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Okfv_vp_KabM"
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from pandas import DataFrame\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = series.values\n",
    "size = int(len(X) * 0.66)\n",
    "train, test = X[0:size], X[size:len(X)]\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for t in range(len(test)):\n",
    "    model = ARIMA(history, order=(5,1,0))\n",
    "    model_fit = model.fit(disp=0)\n",
    "    output = model_fit.forecast()\n",
    "    yhat = output[0]\n",
    "    predictions.append(yhat)\n",
    "    obs = test[t]\n",
    "    history.append(obs)\n",
    "\n",
    "dataset_TI_df['ARIMA'] = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 178731,
     "status": "ok",
     "timestamp": 1565975822299,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "DC3et1Z8KhL3",
    "outputId": "adada03b-a58b-4ecb-ddd2-4d2014835ea1"
   },
   "outputs": [],
   "source": [
    "error = mean_squared_error(test, predictions)\n",
    "print('Test MSE: %.3f' % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJcsXpEndQa8"
   },
   "source": [
    "MSE issquare root of square of average of difference between actual and predicted prices. In this case they MSE is quite big.(MSE ideally for this data should be between 30 and 100). However I will plot the model and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 179049,
     "status": "ok",
     "timestamp": 1565975823495,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "q00FzNdSLuPB",
    "outputId": "64ccde13-b3bf-4863-934b-de0a2cdd79a4"
   },
   "outputs": [],
   "source": [
    "# Plot the predicted (from ARIMA) and real prices\n",
    "\n",
    "plt.figure(figsize=(12, 6), dpi=100)\n",
    "plt.plot(test, color='black', label='Real')\n",
    "plt.plot(predictions, color='yellow', label='Predicted')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('USD')\n",
    "plt.title('Figure 5: ARIMA model on Amazon stock')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SD9T8ykVHqvJ"
   },
   "source": [
    "**As we can see from Figure 5 ARIMA gives a very good approximation of the real stock price. We will use the predicted price through ARIMA as an input feature into the LSTM because, as we mentioned before, we want to capture as many features and patterns about Amazon as possible.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176895,
     "status": "ok",
     "timestamp": 1565975823498,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "3RN-h8RCLyoa",
    "outputId": "29f46fd9-1814-4d2d-8dcd-f62435f71bde"
   },
   "outputs": [],
   "source": [
    "dataset_ex_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 174800,
     "status": "ok",
     "timestamp": 1565975823500,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "lUk-WoQNL2mX",
    "outputId": "f4fd88bf-0369-46c7-ce38-4862139882ab"
   },
   "outputs": [],
   "source": [
    "print('Total dataset has {} samples, and {} features.'.format(dataset_ex_df.shape[0], \\\n",
    "                                                              dataset_ex_df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WcgZYHjdJCI1"
   },
   "source": [
    "# **FINDING IMPORTANT FEATURES USING XGBOOST :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xB0kgHi1L-Hy"
   },
   "source": [
    "**Having so many features we have to consider whether all of them are really indicative of the direction GS stock will take. For example, we included USD denominated LIBOR rates in the dataset because we think that changes in LIBOR might indicate changes in the economy, that, in turn, might indicate changes in the AMZN stock behavior. But we need to test. There are many ways to test feature importance, but the one we will apply uses XGBoost, because it gives one of the best results in both classification and regression problems.**\n",
    "\n",
    "\n",
    "**Since the features dataset is quite large, for the purpose of the presentation here we’ll use only the technical indicators. During the real features importance testing all selected features proved somewhat important so we won’t exclude anything when training.**\n",
    "\n",
    "\n",
    "**So, after adding all types of data (the correlated assets, technical indicators, fundamental analysis, Fourier, and Arima) we have a total of 20 features for the 2,265 days (as mentioned before, however, only 1,585 days are for training data).**\n",
    "\n",
    "**What is XGBoost?**\n",
    "\n",
    "**XGBoost is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework. In prediction problems involving unstructured data (images, text, etc.) artificial neural networks tend to outperform all other algorithms or frameworks. However, when it comes to small-to-medium structured/tabular data, decision tree based algorithms are considered best-in-class right now.**\n",
    "\n",
    "![alt text](https://miro.medium.com/max/1094/1*QJZ6W-Pck_W7RlIDwUIN9Q.jpeg)\n",
    "\n",
    "**WHY DOES XGBOOST WORK SO WELL?\n",
    "XGBoost and Gradient Boosting Machines (GBMs) are both ensemble tree methods that apply the principle of boosting weak learners (CARTs generally) using the gradient descent architecture. However, XGBoost improves upon the base GBM framework through systems optimization and algorithmic enhancements.**\n",
    "\n",
    "![alt text](https://miro.medium.com/max/1094/1*FLshv-wVDfu-i54OqvZdHg.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0DntZYGaL6ct"
   },
   "outputs": [],
   "source": [
    "def get_feature_importance_data(data_income):\n",
    "    data = data_income.copy()\n",
    "    y = data['Close']\n",
    "    X = data.iloc[:,1:19]\n",
    "    \n",
    "    train_samples = int(X.shape[0] * 0.65)\n",
    " \n",
    "    X_train = X.iloc[:train_samples]\n",
    "    X_test = X.iloc[train_samples:]\n",
    "\n",
    "    y_train = y.iloc[:train_samples]\n",
    "    y_test = y.iloc[train_samples:]\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JbO2whZDMCnB"
   },
   "outputs": [],
   "source": [
    "# Get training and test data\n",
    "(X_train_FI, y_train_FI), (X_test_FI, y_test_FI) = get_feature_importance_data(dataset_TI_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6713TYO_MG5q"
   },
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor(gamma=0.0,n_estimators=200,base_score=0.7,colsample_bytree=1,learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 166965,
     "status": "ok",
     "timestamp": 1565975823971,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "1L80xmtDMJT3",
    "outputId": "8800f2e6-5a04-4e94-abc2-f98935932fe6"
   },
   "outputs": [],
   "source": [
    "xgbModel = regressor.fit(X_train_FI,y_train_FI, \\\n",
    "                         eval_set = [(X_train_FI, y_train_FI), (X_test_FI, y_test_FI)], \\\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJrFL2AnMMBy"
   },
   "outputs": [],
   "source": [
    "eval_result = regressor.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-TjzmQqMRBW"
   },
   "outputs": [],
   "source": [
    "training_rounds = range(len(eval_result['validation_0']['rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 163908,
     "status": "ok",
     "timestamp": 1565975823979,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "SohU7-lPMTou",
    "outputId": "9ecf131e-c215-45d6-b9d7-9786d85200a7"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x=training_rounds,y=eval_result['validation_0']['rmse'],label='Training Error')\n",
    "plt.scatter(x=training_rounds,y=eval_result['validation_1']['rmse'],label='Validation Error')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Training Vs Validation Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYixeciceYEg"
   },
   "source": [
    "**THE DIFFERENCE BETWEEN VALIDATION AND TRAINING ERROR SHOWS A UNDERFIT MODEL. EXPECTED AS SAID BEFORE BECAUSE OF THE WAY TRAINING AND TESTING DATA IS SPLIT JUST WHEN AMAZON BOOMS!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 161964,
     "status": "ok",
     "timestamp": 1565975823980,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "U6LISsSkMWat",
    "outputId": "bbea72ef-5f13-40df-baab-647ad72a9df1"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.bar([i for i in range(len(xgbModel.feature_importances_))], xgbModel.feature_importances_.tolist(), tick_label=X_test_FI.columns)\n",
    "plt.title('Figure 6: Feature importance of the technical indicators.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3kdzMlIN8bV"
   },
   "source": [
    "**Not surprisingly (for those with experience in stock trading) that MA7, MA21, and EMA are among the important features.\n",
    "I followed the same logic for performing feature importance over the whole dataset — just the training took longer and results were a little more difficult to read, as compared with just a handful of features.\n",
    "Features like Open and Adj Close are bound to be close to Closing prices\n",
    "So if EMA doesn't works out we will focus on Averaging prices from Open and Adj-CLose prices**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-2dlboKLMowU"
   },
   "source": [
    "**Next steps:\n",
    "We know which features are important. I suspect Fourier and ARIMA might be equally important but because of their\n",
    "spectral component Fourier and because ARIMA doesn't produce any other features I won't be consideringthem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mjFYYdr-f5k9"
   },
   "source": [
    "Code Ref for XGBoost:\n",
    "1. https://xgboost.readthedocs.io/en/latest/get_started.html\n",
    "2. https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKqOo5rfNM6_"
   },
   "source": [
    "# **LSTM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vlHf2osb7LE"
   },
   "source": [
    "**LSTM is great at predicting stock market data. We are going to try to predict the closing prices using 1 feature Open(It has highest correlation to closing price) initially and then using multiple features(use some sort of one hot encoding) and then try to get a output.**\n",
    "\n",
    "**An LSTM Network has its origin in a RNN. But it can solve the memory loss by changing the neuron architecture.**\n",
    "\n",
    "![alt text](https://miro.medium.com/max/875/1*8nFrwolzTYtUWSaziiJGkg.png)\n",
    "\n",
    "**The new neuron has 3 gates, each with a different goal. The gates are:**\n",
    "\n",
    "**1.Input Gate**\n",
    "\n",
    "**2.Output Gate**\n",
    "\n",
    "**3.Forget Gate**\n",
    "\n",
    "**An LSTM Neuron still receives as input its previous state:**\n",
    "\n",
    "**LSTM Neuron passing as parameter its previous state.**\n",
    "\n",
    "![alt text](https://miro.medium.com/max/875/1*J5W8FrASMi93Z81NlAui4w.png)\n",
    "\n",
    "\n",
    "**Following steps are done:**\n",
    "\n",
    "**1.  Clean up the data-Remove any NAs**\n",
    "\n",
    "**2.   Create a test, train and validate set**\n",
    "\n",
    "**3.   Create train for Open**\n",
    "\n",
    "**4.   Normalize data** \n",
    "\n",
    "**5.Create feature and label set**\n",
    "\n",
    "**6. Train, test data and  check with validation set**\n",
    "\n",
    "**7. Make a prediction**\n",
    "\n",
    "**8. Based on this prediction find if the feature extraction method of LSTM works**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 133887,
     "status": "ok",
     "timestamp": 1565975823983,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "S6ylerVkNzKh",
    "outputId": "38d3d7d2-4fb6-49b4-98fd-380a1953f44c"
   },
   "outputs": [],
   "source": [
    "#1. take dataframe and drop na\n",
    "dataset_lstm_df = dataset_TI_df.drop(columns='Date')\n",
    "dataset_lstm_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1205,
     "status": "ok",
     "timestamp": 1565976388705,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "LN2zR8p2NR58",
    "outputId": "700d8bd3-5a4f-464c-9b1a-2a1137d249a8"
   },
   "outputs": [],
   "source": [
    "print('Total dataset has {} samples, and {} features.'.format(dataset_lstm_df.shape[0], \\\n",
    "                                                              dataset_lstm_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2128,
     "status": "ok",
     "timestamp": 1565976391569,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "4jspfamWQaXs",
    "outputId": "c30950a4-0831-49d4-9d96-a8f93722c584"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZoEiTOswgpvE"
   },
   "outputs": [],
   "source": [
    "#creating test, train and validate trains\n",
    "train, validate, test = np.split(dataset_lstm_df.sample(frac=1), [int(.6*len(dataset_lstm_df)), int(.8*len(dataset_lstm_df))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Xw3oUy5ghHW"
   },
   "source": [
    "**Split dataset into train,test and validate sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9J6B42cRFYy"
   },
   "outputs": [],
   "source": [
    "open_training = train.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RQDiGIMt1Wj"
   },
   "source": [
    "**Normalize data:\n",
    "The data is not normalized and the range for each column varies, especially Volume. Normalizing data helps the algorithm in converging i.e. to find local/ global minimum efficiently. I will use MinMaxScaler from Sci-kit Learn. Use a range to keep values similar for that much range**\n",
    "\n",
    "**Keep a window for the length 2000 for your data between 50 and 500...since our length is slightly more than 2000 ill make it 60 to 450**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Dik4lFzRJL-"
   },
   "outputs": [],
   "source": [
    "#normalise\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "open_training = scaler.fit_transform(open_training)\n",
    "#convert to right shape\n",
    "features_set_1 = []\n",
    "labels_1 = []\n",
    "for i in range(60,450): \n",
    "    features_set_1.append(open_training[i-60:i, 0])\n",
    "    labels_1.append(open_training[i, 0])\n",
    "    \n",
    "#Code ref: https://github.com/LiamConnell/deep-algotrading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "en50MEmiuIxV"
   },
   "source": [
    "**Convert feature set and label set into arrays and shape feature set into a 3D input that LSTM network demands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O2JRCdt8RMIb"
   },
   "outputs": [],
   "source": [
    "features_set_1, labels_1 = np.array(features_set_1), np.array(labels_1)\n",
    "features_set_1 = np.reshape(features_set_1, (features_set_1.shape[0], features_set_1.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 425285,
     "status": "ok",
     "timestamp": 1565976824282,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "ShsX-jhtRPZr",
    "outputId": "7d38c480-1feb-4c16-e83b-01ebd9d1693f"
   },
   "outputs": [],
   "source": [
    "#training it\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(features_set_1.shape[1],1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 1))\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['mean_absolute_error'])\n",
    "model.fit(features_set_1, labels_1, epochs = 100, batch_size = 32,validation_data = (features_set_1, labels_1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5aWIT43vX27"
   },
   "source": [
    "**MAE: This means the average difference between input and ouput for all 2265 datapoints is 0.167. \n",
    "However the value is for the days here so the MAE here is pretty bad.(2265 length of dataset will be denominator. Difference between actual and prediced values should be so small that such a large denominator dividing the difference should put MAE in rage of 10^-3 ie 0.00then digits. Since MAE is 167.something*10^-3(0.167) difference is high**\n",
    "\n",
    "\n",
    "**Data is trained for 100 epochs optimizer is adam and loss is mse. This seems to be an average model because mean absolute error is 0.18 and val mean absolute eroor is 0.17 so it indicates overfitting. Since this is a regression problem accuracy is not a good metric. MAE was chosen since the difference between training and testing should be less so we don't need to take the square root of the value.** \n",
    "\n",
    "**We will focus on hyperparameters if this model is good at prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-5yfE6JRRqD"
   },
   "outputs": [],
   "source": [
    "#TESTING THE MODEL\n",
    "open_testing_processed = test.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CHZUOE1uv2i9"
   },
   "source": [
    "**Test the model on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MKcZZryvKReB"
   },
   "outputs": [],
   "source": [
    "#convert test data to right format\n",
    "open_total = pd.concat((train['Open'], test['Open']), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gN7qc_6uv9ta"
   },
   "source": [
    "**Start predictions:\n",
    "Reshape, scale and then oredict the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zjnBY-HKWNN"
   },
   "outputs": [],
   "source": [
    "test_inputs = open_total[len(open_total) - len(test) - 60:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Ot9WW7PKZnE"
   },
   "outputs": [],
   "source": [
    "#scaling data\n",
    "test_inputs = test_inputs.reshape(-1,1)\n",
    "test_inputs = scaler.transform(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xfBTp0XfKd_N"
   },
   "outputs": [],
   "source": [
    "test_features = []\n",
    "for i in range(60, 151):\n",
    "    test_features.append(test_inputs[i-60:i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QwY1URr5KhEo"
   },
   "outputs": [],
   "source": [
    "test_features = np.array(test_features)\n",
    "test_features.shape\n",
    "test_features = np.reshape(test_features, (test_features.shape[0], test_features.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_Zthb6IKjuy"
   },
   "outputs": [],
   "source": [
    "#make predictions\n",
    "predictions = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gn9GJRFoineD"
   },
   "outputs": [],
   "source": [
    "predictions = scaler.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PehVpGNAwc70"
   },
   "source": [
    "**Plot the prediction model for the number of test days and train days**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1034,
     "status": "ok",
     "timestamp": 1565977303541,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "cPa6q0vVKnX3",
    "outputId": "8d6e552a-fb37-411f-a417-998876057386"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(open_testing_processed, color='pink', label='Actual Stock Price')\n",
    "plt.plot(predictions , color='yellow', label='Predicted Stock Price')\n",
    "plt.title('Actual Value vs Predicted')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QNz7cSfbwyby"
   },
   "source": [
    "**This wasn't a great result with one feature so let's try using more features and then train them on LSTM model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jlnOEFRAjjPM"
   },
   "source": [
    "**USING 5FEATURES :**\n",
    "\n",
    "\n",
    "**USING THE BEST 5 FEATURES FROM THE RESULT OF THE XGBOOST. ITS QUITE OBVIOUS THAT A SINGLE FEATURE WILL NOT WORK SO WE USE THE 6 FEATURES THAT\n",
    "COULD GENERATE THE BEST OUTCOME FROM XGBOOST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4sxE7ubqKuI6"
   },
   "outputs": [],
   "source": [
    "dataset = dataset_ex_df[['Open', 'Close','High','Adj Close','Low']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1565977308091,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "CMVCWkeJjrb5",
    "outputId": "16d65690-6c7f-4264-e12b-c8d9cda9dbfb"
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IcdIP_gtw9DB"
   },
   "outputs": [],
   "source": [
    "# FUNCTION TO CREATE 1D DATA INTO TIME SERIES DATASET\n",
    "def new_dataset(dataset, step_size):\n",
    "\tdata_X, data_Y = [], []\n",
    "\tfor i in range(len(dataset)-step_size-1):\n",
    "\t\ta = dataset[i:(i+step_size), 0]\n",
    "\t\tdata_X.append(a)\n",
    "\t\tdata_Y.append(dataset[i + step_size, 0])\n",
    "\treturn np.array(data_X), np.array(data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ovu8nAJxFRb"
   },
   "outputs": [],
   "source": [
    "# IMPORTING IMPORTANT LIBRARIES\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MR5ZH2cUxKpv"
   },
   "outputs": [],
   "source": [
    "# FOR REPRODUCIBILITY\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HEBGkQJQxNrF"
   },
   "outputs": [],
   "source": [
    "# IMPORTING DATASET \n",
    "dataset = dataset.reindex(index = dataset.index[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qjQJZJx-xQOY"
   },
   "outputs": [],
   "source": [
    "# CREATING OWN INDEX FOR FLEXIBILITY\n",
    "obs = np.arange(1, len(dataset) + 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFjIZMzJxUFR"
   },
   "outputs": [],
   "source": [
    "# TAKING DIFFERENT INDICATORS FOR PREDICTION\n",
    "OHLC_avg = dataset.mean(axis = 1)\n",
    "HLC_avg = dataset[['High', 'Low', 'Close']].mean(axis = 1)\n",
    "close_val = dataset[['Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1436,
     "status": "ok",
     "timestamp": 1565977315547,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "MduBu78PxXYX",
    "outputId": "775c954d-6d5b-490c-b07d-d04cde4f8cf1"
   },
   "outputs": [],
   "source": [
    "# PLOTTING All INDICATORS IN PLOT\n",
    "plt.plot(OHLC_avg, 'yellow', label = 'OHLC avg')\n",
    "plt.plot(close_val, 'blue', label = 'Closing price')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('OHLC average')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1108,
     "status": "ok",
     "timestamp": 1565977317476,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "dvM1ej2vxfHQ",
    "outputId": "848b5066-70bc-4894-d459-389bb90b6390"
   },
   "outputs": [],
   "source": [
    "plt.plot(HLC_avg, 'red', label = 'HLC avg')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('HLC average')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 652,
     "status": "ok",
     "timestamp": 1565977318119,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "yRwx0FA8ycRW",
    "outputId": "25d80acc-f214-4607-fdf7-e261aa4cfb1d"
   },
   "outputs": [],
   "source": [
    "plt.plot(close_val, 'blue', label = 'Closing price')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Closing Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8Dx3owPynMb"
   },
   "outputs": [],
   "source": [
    "# PREPARATION OF TIME SERIES DATASE\n",
    "OHLC_avg = np.reshape(OHLC_avg.values, (len(OHLC_avg),1)) \n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "OHLC_avg = scaler.fit_transform(OHLC_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9HAD1oZozwym"
   },
   "outputs": [],
   "source": [
    "# TRAIN-TEST SPLIT\n",
    "train_OHLC = int(len(OHLC_avg) * 0.75)\n",
    "test_OHLC = len(OHLC_avg) - train_OHLC\n",
    "train_OHLC, test_OHLC = OHLC_avg[0:train_OHLC,:], OHLC_avg[train_OHLC:len(OHLC_avg),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yet5xNOoz0x-"
   },
   "outputs": [],
   "source": [
    "# TIME-SERIES DATASET (FOR TIME T, VALUES FOR TIME T+1)\n",
    "trainX, trainY = new_dataset(train_OHLC, 1)\n",
    "testX, testY = new_dataset(test_OHLC, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHbI5KDKz4W7"
   },
   "outputs": [],
   "source": [
    "# RESHAPING TRAIN AND TEST DATA\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "step_size = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ycBSKqy9z78c"
   },
   "outputs": [],
   "source": [
    "# LSTM MODEL\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(1, step_size), return_sequences = True))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 794197,
     "status": "ok",
     "timestamp": 1565978117682,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "eW5inyg0z_b1",
    "outputId": "788810cb-6ecb-4202-b77d-f017603f0db5"
   },
   "outputs": [],
   "source": [
    "# MODEL COMPILING AND TRAINING\n",
    "model.compile(loss='mean_squared_error', optimizer='adagrad',metrics = ['mae']) # Try mae, adam, adagrad and compare!!!\n",
    "model.fit(trainX, trainY, epochs=50, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 898,
     "status": "ok",
     "timestamp": 1565978385230,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "1amjmgWGFICM",
    "outputId": "793002e6-54b1-413c-dde6-efffe6faac8d"
   },
   "outputs": [],
   "source": [
    "mae = model.evaluate(testX, testY, batch_size=16)\n",
    "print('Mean Absolute Error for Y:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yT3NCySy0y7g"
   },
   "source": [
    "**The mean absolute error is lower than the past model with one feature. The errror is almost 0.0026. So the training model should be pretty close to testing model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6uYIJzE_0DxZ"
   },
   "outputs": [],
   "source": [
    "# PREDICTION\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ROLKJGIl2J_e"
   },
   "outputs": [],
   "source": [
    "# DE-NORMALIZING FOR PLOTTING\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1425,
     "status": "ok",
     "timestamp": 1565978407619,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "R-s7kUbd2KNc",
    "outputId": "b0425c17-415a-41a9-a3c7-d3829358f8b9"
   },
   "outputs": [],
   "source": [
    "# TRAINING rmse\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train : %.2f' % (trainScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1565978409272,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "PwM4dL-n2Sfr",
    "outputId": "8ff47f43-5a38-497a-8c43-3dd5a1a3d251"
   },
   "outputs": [],
   "source": [
    "# TEST RMSE\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test RMSE: %.2f' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DwSzCAOg2Sui"
   },
   "outputs": [],
   "source": [
    "# CREATING SIMILAR DATASET TO PLOT TRAINING PREDICTIONS\n",
    "trainPredictPlot = np.empty_like(OHLC_avg)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[step_size:len(trainPredict)+step_size, :] = trainPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNZkZbvS2S8A"
   },
   "outputs": [],
   "source": [
    "# CREATING SIMILAR DATASSET TO PLOT TEST PREDICTIONS\n",
    "testPredictPlot = np.empty_like(OHLC_avg)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(step_size*2)+1:len(OHLC_avg)-1, :] = testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1462,
     "status": "ok",
     "timestamp": 1565978414993,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "uMlLzjbO2KVv",
    "outputId": "73e936bf-4275-49e1-8a8c-6255c930cfb8"
   },
   "outputs": [],
   "source": [
    "# PLOT OF MAIN OHLC VALUES, TRAIN PREDICTIONS AND TEST PREDICTIONS\n",
    "plt.plot(trainPredictPlot, 'r', label = 'training set')\n",
    "plt.plot(testPredictPlot, 'b', label = 'predicted stock price/test set')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.xlabel('Time in Days')\n",
    "plt.ylabel('Trend of training and prediction data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zHx-W08B2wps"
   },
   "source": [
    "**We trained our data for the first 1700 or so days and then tested for the rest. The prediction plot has kept up with the pattern how ever not to my satisfaction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1560,
     "status": "ok",
     "timestamp": 1565978422972,
     "user": {
      "displayName": "Nupur Deshpande",
      "photoUrl": "",
      "userId": "13787757531456301957"
     },
     "user_tz": 240
    },
    "id": "C5SQ_pi82KS5",
    "outputId": "053cd7ec-42f0-452d-cc86-768e0a88531c"
   },
   "outputs": [],
   "source": [
    "# PREDICT FUTURE VALUES\n",
    "last_val = testPredict[-1]\n",
    "last_val_scaled = last_val/last_val\n",
    "next_val = model.predict(np.reshape(last_val_scaled, (1,1,1)))\n",
    "print(\"Last Day Value:\", np.asscalar(last_val))\n",
    "print(\"Next Day Value:\", np.asscalar(last_val*next_val))\n",
    "# print np.append(last_val, next_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IXmqKOhv5k_4"
   },
   "source": [
    "**The value  was found  relying on OHLC values. As the days increase the value is decreasing or rather stabilizing. However this is a wrong way of going about since amazon prices are still booming not decreasing.**\n",
    "\n",
    "**Next notebook I'll focus on NOT overfitting the model and trying to get more data. Also I'll perform hyperparameter tuning and then try to PREDICT the STOCK PRICE MOVEMENT instead of the prices** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j4UZTgxim3s7"
   },
   "source": [
    "  Code Ref for LSTM:\n",
    "  \n",
    "  https://github.com/LiamConnell/deep-algotrading\n",
    "  \n",
    "  https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bWkl-qKK8p4s"
   },
   "source": [
    "**IN THE NEXT NOTEBOOK I AM GOING TO FOCUS MORE ON NORMALIZATION WITH HYPERPARAMTER TUNING AND LESS ON FEATURE EXTRACTION. THE REASON FOR THIS IS IT LOOKS LIKE A LSTM ESPECIALLY ON KERAS DOESN'T DO A GREAT JOB AT PREDICTING DAY TO DAY VALUES.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uYzRzdkT1xbz"
   },
   "source": [
    "**CONCLUSION FOR THIS NOTEBOOK:**\n",
    "\n",
    "**1. FEATURES**:\n",
    "\n",
    "**Focused on feature engineering and made a total of 19 features. Most of them were based on momentum and moving avaerage and EMA. Even Bollinger Bands were calculated**\n",
    "\n",
    "**2. ARIMA MODEL**\n",
    "\n",
    "**Got a great ARIMA model with less differemce AIC and BIC and P values close to the coefficient**\n",
    "\n",
    "**3. FOURIER TRANSFORM MODEL**\n",
    "\n",
    "**We got great predictions with Fourier Transform very close to the actual values**\n",
    "\n",
    "**4. FEATURE ENGINEERING WITH XGBOOST**\n",
    "\n",
    "**Refer to feature extraction graph where features are highest by their closeness to their Closing values. As predicted EMA is pretty high in this feature.** \n",
    "\n",
    "**5. LSTM MODEL WITH ONE FEATURE** \n",
    "\n",
    "**LSTM model with one feature did NOT give us the predictions we wanted.**\n",
    "\n",
    "**6. LSTM MODEL WITH MULTIPLE FEATURES**\n",
    "\n",
    "**LSTM model with multiple features again did not give us predictions we wanted.**\n",
    "\n",
    "**I have come to the conclusion that LSTMs are not great at predicting Stock Prices when you just input stock price directly but rather better at predicting stock price movement over a long period of time.With the help of these movements we can calclate the price.**\n",
    "\n",
    "**For this reason  I will use a larger dataset in the next notebook that can be observed for longer time and then predict stock price movement**\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Notebook 1: Stock Market Models-ARIMA, Fourier, Feature Extraction, LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
